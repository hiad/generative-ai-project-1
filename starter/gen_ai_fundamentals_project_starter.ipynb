{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Project: Teaching an LLM to Reason\n",
        "\n",
        "In this project, you will teach an LLM to use step-by-step reasoning to answer the question: \"How many X's are there in the word Y?\"\n",
        "\n",
        "Counting letters in a word is a surprisingly complex task for an LLM. Just as human beings would not be able to answer such a question for longer words without breaking down the word into its individual letters and then counting them, LLMs cannot be similarly expected to be able to respond without using smaller reasoning steps.\n",
        "\n",
        "For example, to count the number of o's in the word room, one could use the following reasoning:\n",
        "\n",
        "```\n",
        "Question: How many of the letter \"o\" are there in the word \"room\"\n",
        "Answer: 2\n",
        "Response:\n",
        "\n",
        "<reasoning>\n",
        "Letter-by-letter spelling:\n",
        "1. r - 0 o's so far\n",
        "2. o - 1 o's so far\n",
        "3. o - 2 o's so far\n",
        "4. m - 2 o's so far\n",
        "\n",
        "The letter \"o\" appears 2 times in the word \"room\".\n",
        "</reasoning>\n",
        "<answer>\n",
        "2\n",
        "</answer>\n",
        "```\n",
        "\n",
        "In this project we will use the reinforcement learning method GRPO (Group Relative Policy Optimization, of DeepSeek fame) to take a large language model that has been fine-tuned for following instructions and teach it how to break a word down into its letters and then count the requested letter.\n",
        "\n",
        "We will complete the following steps:\n",
        "\n",
        "* Set up the notebook\n",
        "* Create a letter-counting dataset\n",
        "* Create the reward functions\n",
        "* Train the model\n",
        "* View the results\n",
        "\n",
        "NOTE: This notebook will have you focus on several important aspects of training a GPRO model using LoRA:\n",
        "\n",
        "1. Configuring LoRA adapters for parameter-efficient fine tuning\n",
        "2. Selecting reward functions that help the model efficiently find its way to the correct answer (also called reward shaping)\n",
        "3. Finding hyperparameters that help the model increase the rewards earned more quickly and reliably\n",
        "4. Learning how to start with smaller experiments and to work your way up to longer experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up the notebook\n",
        "\n",
        "We'll install dependencies needed for the project, namely `unsloth` and `vllm`, which are useful for fine-tuning LLMs with even just 15GB of VRAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 212 Î¼s (started: 2025-12-26 19:17:41 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Load ipython-autotime to see how long each cell take to run\n",
        "# No changes needed in this cell\n",
        "\n",
        "!pip install -q ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Dec 26 19:17:41 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       On  |   00000000:00:1E.0 Off |                    0 |\n",
            "| N/A   23C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 315 ms (started: 2025-12-26 19:17:41 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Verify we have enough GPU memory to run this project (at least 15360MiB)\n",
        "# No changes needed in this cell\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/voc/data/venv2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "INFO 12-26 19:18:31 [__init__.py:241] Automatically detected platform cuda.\n",
            "ERROR 12-26 19:18:35 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "INFO 12-26 19:19:02 [vllm_utils.py:688] Unsloth: Patching vLLM v1 graph capture\n",
            "INFO 12-26 19:19:02 [vllm_utils.py:716] Unsloth: Patching vLLM v0 graph capture\n",
            "==((====))==  Unsloth 2025.9.7: Fast Qwen2 patching. Transformers: 4.55.4. vLLM: 0.10.1.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.563 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: vLLM loading unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit with actual GPU utilization = 49.52%\n",
            "Unsloth: Your GPU has CUDA compute capability 7.5 with VRAM = 14.56 GB.\n",
            "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 456. Num Sequences = 192.\n",
            "Unsloth: vLLM's KV Cache can use up to 4.96 GB. Also swap space = 0 GB.\n",
            "WARNING 12-26 19:19:03 [compilation.py:453] full_cuda_graph is deprecated, use cudagraph_mode=FULL instead.\n",
            "Unsloth: Not an error, but `device` is not supported in vLLM. Skipping.\n",
            "INFO 12-26 19:19:03 [utils.py:326] non-default args: {'model': 'unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit', 'load_format': 'bitsandbytes', 'dtype': torch.float16, 'seed': 0, 'max_model_len': 456, 'enable_prefix_caching': True, 'swap_space': 0, 'gpu_memory_utilization': 0.4952075204419056, 'max_num_batched_tokens': 2048, 'max_num_seqs': 192, 'max_logprobs': 0, 'disable_log_stats': True, 'quantization': 'bitsandbytes', 'enable_lora': True, 'enable_chunked_prefill': True, 'compilation_config': {\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"inductor\",\"custom_ops\":[],\"splitting_ops\":null,\"use_inductor\":true,\"compile_sizes\":null,\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":false,\"trace.graph_diagram\":false,\"compile_threads\":4,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":false,\"triton.cooperative_reductions\":false,\"cuda.compile_opt_level\":\"-O2\",\"cuda.enable_cuda_lto\":true,\"combo_kernels\":false,\"benchmark_combo_kernel\":true,\"combo_kernel_foreach_dynamic_shapes\":true,\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":2,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":null,\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":true,\"pass_config\":{},\"max_capture_size\":null,\"local_cache_dir\":null}}\n",
            "INFO 12-26 19:19:31 [__init__.py:711] Resolved architecture: Qwen2ForCausalLM\n",
            "WARNING 12-26 19:19:31 [__init__.py:2819] Casting torch.bfloat16 to torch.float16.\n",
            "INFO 12-26 19:19:31 [__init__.py:1750] Using max model len 456\n",
            "WARNING 12-26 19:19:31 [arg_utils.py:1770] Compute Capability < 8.0 is not supported by the V1 Engine. Falling back to V0. \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-26 19:19:33,679\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 12-26 19:19:34 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=2048.\n",
            "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'float16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection', 'model.layers.2.mlp', 'model.layers.3.mlp', 'model.layers.30.mlp'], 'llm_int8_threshold': 6.0}\n",
            "INFO 12-26 19:19:34 [llm_engine.py:222] Initializing a V0 LLM engine (v0.10.1) with config: model='unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit', speculative_config=None, tokenizer='unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=456, download_dir=None, load_format=bitsandbytes, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"inductor\",\"custom_ops\":[],\"splitting_ops\":null,\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":false,\"trace.graph_diagram\":false,\"compile_threads\":4,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":false,\"triton.cooperative_reductions\":false,\"cuda.compile_opt_level\":\"-O2\",\"cuda.enable_cuda_lto\":true,\"combo_kernels\":false,\"benchmark_combo_kernel\":true,\"combo_kernel_foreach_dynamic_shapes\":true,\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":2,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":true,\"pass_config\":{\"enable_fusion\":false,\"enable_noop\":false},\"max_capture_size\":192,\"local_cache_dir\":null}, use_cached_outputs=False, \n",
            "INFO 12-26 19:19:35 [cuda.py:384] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "INFO 12-26 19:19:35 [cuda.py:433] Using XFormers backend.\n",
            "INFO 12-26 19:19:36 [parallel_state.py:1134] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
            "INFO 12-26 19:19:36 [model_runner.py:1080] Starting to load model unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit...\n",
            "INFO 12-26 19:19:37 [bitsandbytes_loader.py:742] Loading weights with BitsAndBytes quantization. May take a while ...\n",
            "INFO 12-26 19:19:37 [weight_utils.py:296] Using model weights format ['*.safetensors']\n",
            "INFO 12-26 19:19:38 [weight_utils.py:349] No model.safetensors.index.json found in remote.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.89s/it]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.90s/it]\n",
            "\n",
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:17<00:00, 17.90s/it]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:17<00:00, 17.90s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 12-26 19:19:57 [punica_selector.py:19] Using PunicaWrapperGPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 12-26 19:19:58 [model_runner.py:1112] Model loading took 2.2719 GiB and 21.547419 seconds\n",
            "INFO 12-26 19:20:04 [worker.py:295] Memory profiling takes 4.93 seconds\n",
            "INFO 12-26 19:20:04 [worker.py:295] the current vLLM instance can use total_gpu_memory (14.56GiB) x gpu_memory_utilization (0.50) = 7.21GiB\n",
            "INFO 12-26 19:20:04 [worker.py:295] model weights take 2.27GiB; non_torch_memory takes 0.03GiB; PyTorch activation peak memory takes 1.05GiB; the rest of the memory reserved for KV Cache is 3.86GiB.\n",
            "INFO 12-26 19:20:04 [executor_base.py:114] # cuda blocks: 7029, # CPU blocks: 0\n",
            "INFO 12-26 19:20:04 [executor_base.py:119] Maximum concurrency for 456 tokens per request: 246.63x\n",
            "INFO 12-26 19:20:04 [vllm_utils.py:721] Unsloth: Running patched vLLM v0 `capture_model`.\n",
            "INFO 12-26 19:20:04 [model_runner.py:1383] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Capturing CUDA graph shapes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:12<00:00,  2.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 12-26 19:20:17 [model_runner.py:1535] Graph capturing finished in 13 secs, took 0.56 GiB\n",
            "INFO 12-26 19:20:17 [vllm_utils.py:728] Unsloth: Patched vLLM v0 graph capture finished in 13 secs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 12-26 19:20:17 [llm_engine.py:417] init engine (profile, create kv cache, warmup model) took 19.00 seconds\n",
            "INFO 12-26 19:20:17 [llm.py:298] Supported_tasks: ['generate']\n",
            "Unsloth: Just some info: will skip parsing ['q_norm', 'layer_norm2', 'post_layernorm', 'norm2', 'layer_norm1', 'input_layernorm', 'k_norm', 'post_feedforward_layernorm', 'pre_feedforward_layernorm', 'norm1', 'post_attention_layernorm']\n",
            "Unsloth: Just some info: will skip parsing ['q_norm', 'layer_norm2', 'post_layernorm', 'norm2', 'cross_attn_input_layernorm', 'layer_norm1', 'input_layernorm', 'k_norm', 'post_feedforward_layernorm', 'pre_feedforward_layernorm', 'norm1', 'cross_attn_post_attention_layernorm', 'post_attention_layernorm']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.9.7 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 2min 47s (started: 2025-12-26 19:17:41 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Load the `Qwen 2.5 3B Instruct`, and set parameters for the project\n",
        "# The first time unsloth is imported, it will do its magic and patch the modules\n",
        "# it works with. This may 2-5 minutes.\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "import unsloth\n",
        "\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "max_seq_length = 456  # Increase if you get errors about the sequence length\n",
        "\n",
        "# Set the LoRA rank to an appropriate value\n",
        "# Read about setting LoRA rank:\n",
        "# https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/lora-hyperparameters-guide\n",
        "lora_rank = 16\n",
        "\n",
        "# Load the Instruct model in 4-bit mode\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"Qwen/Qwen2.5-3B-Instruct\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    load_in_4bit=True,  # We'll use quantization!\n",
        "    fast_inference=True,  # This uses vllm for faster inference\n",
        "    max_lora_rank=lora_rank,\n",
        "    gpu_memory_utilization=0.5,  # You can reduce this if you get an memory error\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=lora_rank,\n",
        "    target_modules=[\n",
        "        'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj'\n",
        "    ],\n",
        "    lora_alpha=lora_rank,\n",
        "    use_gradient_checkpointing=\"unsloth\",  # Unsloth enables longer contexts\n",
        "    # See: https://github.com/unslothai/unsloth\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Try Prompt Engineering to Count Letters\n",
        "\n",
        "Let's work on the system prompt a little to see if we can get the model to count the number of the letter `g` in `engage`.\n",
        "\n",
        "\n",
        "Here you must:\n",
        "* Write clear instructions\n",
        "* Break the problem down into steps (Chain-of-Thought prompting)\n",
        "* Provide at least one example for the model to follow (Few-shot prompting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1136.05it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.42it/s, est. speed input: 41.29 toks/s, output: 21.35 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== TEXT FOR COMPLETION ===\n",
            "<|im_start|>system\n",
            "<|im_end|>\n",
            "<|im_start|>user\n",
            "How many of the letter \"g\" are there in the word \"engage\"<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n",
            "=== GENERATED OUTPUT ===\n",
            "In the word \"engage\", there is only one letter \"g\".\n",
            "time: 711 ms (started: 2025-12-26 19:20:29 +00:00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# First, let's see what happens when we have a blank system prompt\n",
        "# No changes needed in this cell\n",
        "SYSTEM_PROMPT = \"\"\"\"\"\"\n",
        "USER_PROMPT = 'How many of the letter \"g\" are there in the word \"engage\"'\n",
        "\n",
        "# Convert the chat messages to a single string so the model can complete it\n",
        "text_for_completion = tokenizer.apply_chat_template(\n",
        "    conversation=[\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": USER_PROMPT,\n",
        "        },\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True,\n",
        ")\n",
        "\n",
        "from vllm import SamplingParams\n",
        "\n",
        "# Set the LLM sampling parameters\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        "    max_tokens=2048,\n",
        ")\n",
        "\n",
        "# Generate the text completion\n",
        "output = (\n",
        "    model.fast_generate(\n",
        "        [text_for_completion],\n",
        "        sampling_params=sampling_params,\n",
        "        lora_request=None,\n",
        "    )[0]\n",
        "    .outputs[0]\n",
        "    .text\n",
        ")\n",
        "\n",
        "# Print the text input for the model and the model's output\n",
        "print(\"=== TEXT FOR COMPLETION ===\")\n",
        "print(text_for_completion)\n",
        "print(\"=== GENERATED OUTPUT ===\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Without any prompting the model will generate an output such as this:\n",
        "\n",
        "```\n",
        "=== GENERATED OUTPUT ===\n",
        "There is one letter \"g\" in the word \"engage\".\n",
        "```\n",
        "\n",
        "Now let's work on the system prompt to help the model break this problem down into steps, which might help it get the right answer (2 `g`'s in `engage`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 767.20it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.11it/s, est. speed input: 260.94 toks/s, output: 31.82 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== TEXT FOR COMPLETION ===\n",
            "<|im_start|>system\n",
            "You are an assistant that help with letter countring. Letters can be between A and Z. Go letter by letter \n",
            "and check if the letter is the one asked. Use chain of thought. Use the following example as a correct answer for this exercise.  The output format is There is X letters \"X\" in the word \"X\"\n",
            "Example: Word: Headphones. Answer: There is 2 letters \"e\" in the word \"Headphones\". <|im_end|>\n",
            "<|im_start|>user\n",
            "How many of the letter \"g\" are there in the word \"engage\"<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n",
            "=== GENERATED OUTPUT ===\n",
            "There is 2 letters \"g\" in the word \"engage\".\n",
            "time: 480 ms (started: 2025-12-26 19:20:29 +00:00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's work on a new system prompt that will help the model break this problem\n",
        "# down into steps, for example, using \"letter-by-letter\" spelling.\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "# Use a CoT prompt with at least one example\n",
        "SYSTEM_PROMPT = \"\"\"You are an assistant that help with letter countring. Letters can be between A and Z. Go letter by letter \n",
        "and check if the letter is the one asked. Use chain of thought. Use the following example as a correct answer for this exercise.  The output format is There is X letters \"X\" in the word \"X\"\n",
        "Example: Word: Headphones. Answer: There is 2 letters \"e\" in the word \"Headphones\". \"\"\"\n",
        "\n",
        "\n",
        "USER_PROMPT = 'How many of the letter \"g\" are there in the word \"engage\"'\n",
        "\n",
        "# Convert the chat messages to a single string so the model can complete it\n",
        "text_for_completion = tokenizer.apply_chat_template(\n",
        "    conversation=[\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": USER_PROMPT,\n",
        "        },\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True,\n",
        ")\n",
        "\n",
        "from vllm import SamplingParams\n",
        "\n",
        "# Set the LLM sampling parameters\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        "    max_tokens=2048,\n",
        ")\n",
        "\n",
        "# Generate the text completion\n",
        "output = (\n",
        "    model.fast_generate(\n",
        "        [text_for_completion],\n",
        "        sampling_params=sampling_params,\n",
        "        lora_request=None,\n",
        "    )[0]\n",
        "    .outputs[0]\n",
        "    .text\n",
        ")\n",
        "\n",
        "# Print the text input for the model and the model's output\n",
        "print(\"=== TEXT FOR COMPLETION ===\")\n",
        "print(text_for_completion)\n",
        "print(\"=== GENERATED OUTPUT ===\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Did your new prompt get the right answer? Did the model follow all of your instructions?\n",
        "\n",
        "Maybe yes, maybe no. Either way, we'll want the model to reliably complete this challenge. So let's use GRPO to help it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a letter-counting dataset\n",
        "\n",
        "To train a model, we'll first need to create a dataset. We'll use the HuggingFace `datasets` package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['idea',\n",
              " 'glow',\n",
              " 'rust',\n",
              " 'maze',\n",
              " 'echo',\n",
              " 'wisp',\n",
              " 'veto',\n",
              " 'lush',\n",
              " 'gaze',\n",
              " 'knit']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 5.54 ms (started: 2025-12-26 19:20:30 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Create a list of words of different lengths\n",
        "# No changes are needed in this cell.\n",
        "\n",
        "ALL_WORDS = [\n",
        "    \"idea\",\n",
        "    \"glow\",\n",
        "    \"rust\",\n",
        "    \"maze\",\n",
        "    \"echo\",\n",
        "    \"wisp\",\n",
        "    \"veto\",\n",
        "    \"lush\",\n",
        "    \"gaze\",\n",
        "    \"knit\",\n",
        "    \"fume\",\n",
        "    \"plow\",\n",
        "    \"void\",\n",
        "    \"oath\",\n",
        "    \"grim\",\n",
        "    \"crisp\",\n",
        "    \"lunar\",\n",
        "    \"fable\",\n",
        "    \"quest\",\n",
        "    \"verge\",\n",
        "    \"brawn\",\n",
        "    \"elude\",\n",
        "    \"aisle\",\n",
        "    \"ember\",\n",
        "    \"crave\",\n",
        "    \"ivory\",\n",
        "    \"mirth\",\n",
        "    \"knack\",\n",
        "    \"wryly\",\n",
        "    \"onset\",\n",
        "    \"mosaic\",\n",
        "    \"velvet\",\n",
        "    \"sphinx\",\n",
        "    \"radius\",\n",
        "    \"summit\",\n",
        "    \"banner\",\n",
        "    \"cipher\",\n",
        "    \"glisten\",\n",
        "    \"mantle\",\n",
        "    \"scarab\",\n",
        "    \"expose\",\n",
        "    \"fathom\",\n",
        "    \"tavern\",\n",
        "    \"fusion\",\n",
        "    \"relish\",\n",
        "    \"lantern\",\n",
        "    \"enchant\",\n",
        "    \"torrent\",\n",
        "    \"capture\",\n",
        "    \"orchard\",\n",
        "    \"eclipse\",\n",
        "    \"frescos\",\n",
        "    \"triumph\",\n",
        "    \"absolve\",\n",
        "    \"gossipy\",\n",
        "    \"prelude\",\n",
        "    \"whistle\",\n",
        "    \"resolve\",\n",
        "    \"zealous\",\n",
        "    \"mirage\",\n",
        "    \"aperture\",\n",
        "    \"sapphire\",\n",
        "]\n",
        "\n",
        "print(len(ALL_WORDS))\n",
        "\n",
        "ALL_WORDS[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'words': 'idea', 'letters': 'e', 'counts': 1}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 365 ms (started: 2025-12-26 19:20:30 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Create the dataset as a Hugging Face Dataset using Dataset.from_generator\n",
        "# No changes needed in this cell\n",
        "\n",
        "from datasets import Dataset\n",
        "import random\n",
        "\n",
        "\n",
        "# Go through the letters from the words (as well as letters not in the words),\n",
        "# and create a labelled dataset with all the different combinations.\n",
        "# For example for the word gaze:\n",
        "# 1. How many i's are in idea? <-- count should be 1\n",
        "# 2. How many d's are in idea? <-- count should be 1\n",
        "# 3. How many e's are in idea? <-- count should be 1\n",
        "# 4. How many a's are in idea? <-- count should be 1\n",
        "# 5. How many b's are in idea? <-- a letter not in word (count should be zero)\n",
        "def generate_records():\n",
        "    for word in ALL_WORDS:\n",
        "        for letter in sorted(set(word)):\n",
        "            yield {\"words\": word, \"letters\": letter, \"counts\": word.count(letter)}\n",
        "\n",
        "        # pick random letters not in the word\n",
        "        num_letters_not_in_word_left = int(len(word) // 7 + 1)\n",
        "\n",
        "        random.seed(hash(word))\n",
        "\n",
        "        all_letters = list(\"abcdefghijklmnopqrstuvwxyz\")\n",
        "\n",
        "        random.shuffle(all_letters)\n",
        "        for letter in all_letters:\n",
        "            if letter not in word:\n",
        "                yield {\"words\": word, \"letters\": letter, \"counts\": 0}\n",
        "                num_letters_not_in_word_left -= 1\n",
        "            if num_letters_not_in_word_left == 0:\n",
        "                break\n",
        "\n",
        "\n",
        "ds = Dataset.from_generator(generate_records)\n",
        "\n",
        "# Show the first item\n",
        "ds[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'words': 'idea',\n",
              " 'letters': 'a',\n",
              " 'counts': 1,\n",
              " 'prompt': [{'content': \"\\nRespond in the following format:\\n<reasoning>\\nCounting the number of [letter_to_count]'s in the word [word]\\n1. [first letter] - [count of requested letter so far] so far\\n2. [second letter] - [count of requested letter so far] so far\\n...\\n</reasoning>\\n<answer>\\n[number]\\n</answer>\\n\",\n",
              "   'role': 'system'},\n",
              "  {'content': 'How many of the letter \"a\" are there in the word \"idea\"',\n",
              "   'role': 'user'}]}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 27 ms (started: 2025-12-26 19:20:30 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Add the entire prompt (system + user) and the answer to the dataset\n",
        "# We'll use a prompt that spells out the word letter-by-letter\n",
        "# No changes needed in this cell\n",
        "\n",
        "import re\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# Simple CoT prompt (zero-shot)\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "Respond in the following format:\n",
        "<reasoning>\n",
        "Counting the number of [letter_to_count]'s in the word [word]\n",
        "1. [first letter] - [count of requested letter so far] so far\n",
        "2. [second letter] - [count of requested letter so far] so far\n",
        "...\n",
        "</reasoning>\n",
        "<answer>\n",
        "[number]\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "ds = ds.map(\n",
        "    lambda x: {  # type: ignore\n",
        "        \"prompt\": [\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": 'How many of the letter \"{}\" are there in the word \"{}\"'.format(\n",
        "                    x[\"letters\"], x[\"words\"]\n",
        "                ),\n",
        "            },\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "\n",
        "ds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 877.47it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.64s/it, est. speed input: 63.99 toks/s, output: 39.61 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<reasoning>\n",
            "Counting the number of a's in the word idea\n",
            "1. i - 0 so far\n",
            "2. d - 1 so far\n",
            "3. e - 2 so far\n",
            "4. a - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "time: 1.67 s (started: 2025-12-26 19:20:30 +00:00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's see how well the model runs out-of-the-box\n",
        "# No changes needed in this cell\n",
        "\n",
        "text = tokenizer.apply_chat_template(\n",
        "    ds[0][\"prompt\"], tokenize=False, add_generation_prompt=True\n",
        ")\n",
        "\n",
        "from vllm import SamplingParams\n",
        "\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        "    max_tokens=1024,\n",
        ")\n",
        "output = (\n",
        "    model.fast_generate(\n",
        "        [text],\n",
        "        sampling_params=sampling_params,\n",
        "        lora_request=None,\n",
        "    )[0]\n",
        "    .outputs[0]\n",
        "    .text\n",
        ")\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Reward Functions\n",
        "\n",
        "One goal of creating reward functions is to guide the model toward behaviors that help it reach its goal (counting the occurrences of a letter within a word) more easily. Since there is more than one way to carry out any step-by-step task (e.g. whether or not you use bullet points to separate your steps), there's a bit of judgement involved in choosing what behaviors to reward, i.e. how do we provide partial credit or \"shape\" our rewards?\n",
        "\n",
        "In this case we will encourage the model to (whether or not this structure is best):\n",
        "* use numbers for bullet points when spelling out the word\n",
        "* to spell the word correctly\n",
        "* to count the requested letter correctly\n",
        "* to use the requested reasoning format\n",
        "* to get the final answer correct.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Numbering reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.5, 0.5]\n",
            "time: 2.81 ms (started: 2025-12-26 19:20:32 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Let's work on a function that the numbering in the bullet points is correct\n",
        "# When using GRPO, we lean on reward functions that are relatively easy to\n",
        "# compute, thus removing the need to have a second large model just for\n",
        "# evaluation.\n",
        "# In this case, we'll use regular expressions quite a bit.\n",
        "\n",
        "\n",
        "def extract_letter_numbering(response):\n",
        "    \"\"\"Extract the numbers at the beginning of the line\n",
        "\n",
        "    Example:\n",
        "    1. g - 1 so far\n",
        "    2. o - 1 so far\n",
        "    3. a - 2 so far\n",
        "    4. a - 2 so far\n",
        "    5. l - 2 so far\n",
        "    returns [1, 2, 3, 4, 5]\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    # We use a regular expression to find lines of the form:\n",
        "    # '\\n[number]. [letter]'\n",
        "    pattern = r\"\\n(\\d+). [a-z]\"\n",
        "\n",
        "    # Use `re` to find all matches of the pattern in the response\n",
        "    matches = re.findall(pattern, response, flags=re.IGNORECASE)\n",
        "    if matches:\n",
        "        return [int(m) for m in matches]\n",
        "    return []\n",
        "\n",
        "\n",
        "assert extract_letter_numbering(\n",
        "    \"\"\"\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. a - 2 so far\n",
        "5. l - 2 so far\n",
        "\"\"\"\n",
        ") == [1, 2, 3, 4, 5]\n",
        "\n",
        "\n",
        "def numbering_reward_func(completions, words, **kwargs) -> list[float]:\n",
        "    \"\"\"Provides a reward for getting the numbering at the beginning of the line correct\n",
        "\n",
        "    1. g - 1 so far <-- Good in-order numbering\n",
        "    2. o - 1 so far <-- Good in-order numbering\n",
        "    3. a - 2 so far <-- Good in-order numbering\n",
        "    3. l - 2 so far <-- Bad numbering, out-of-order, 3 should be 4\n",
        "    1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "    1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "\n",
        "    \"\"\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    res = []\n",
        "    for response, word in zip(responses, words):\n",
        "        reward = 0\n",
        "\n",
        "        for ix, spell_number in enumerate(extract_letter_numbering(response)):\n",
        "            line_number = ix + 1\n",
        "\n",
        "            # Get points for in-order numbering\n",
        "            if spell_number == line_number:\n",
        "                reward += 1\n",
        "            else:\n",
        "                reward -= 1\n",
        "\n",
        "            # Lose extra points for continuing beyond the length of the word\n",
        "            if line_number > len(word):  # We use the index of the line\n",
        "                reward -= 1\n",
        "\n",
        "        res.append(reward / len(word))\n",
        "    return res\n",
        "\n",
        "\n",
        "res = numbering_reward_func(\n",
        "    completions=[\n",
        "        [\n",
        "            {  # Worse response\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far <-- Good in-order numbering\n",
        "2. o - 1 so far <-- Good in-order numbering\n",
        "3. a - 2 so far <-- Good in-order numbering\n",
        "3. l - 2 so far <-- Bad numbering, out-of-order, 3 should be 4\n",
        "1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            },\n",
        "        ],\n",
        "        [\n",
        "            {  # Better response\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far <-- Good in-order numbering\n",
        "2. o - 1 so far <-- Good in-order numbering\n",
        "3. a - 2 so far <-- Good in-order numbering\n",
        "3. l - 2 so far <-- Bad numbering, out-of-order, 3 should be 4\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            },\n",
        "        ],\n",
        "    ],\n",
        "    words=[\"goal\", \"goal\"],\n",
        ")\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Spelling reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-2.0, 1.0]\n",
            "time: 42.8 ms (started: 2025-12-26 19:20:32 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Reward correct spelling of the word\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "\n",
        "def extract_spelling(response):\n",
        "    \"\"\"Extract the spelling from the response\n",
        "\n",
        "    Example:\n",
        "    1. g - 1 so far\n",
        "    2. o - 1 so far\n",
        "    3. a - 2 so far\n",
        "    3. l - 2 so far\n",
        "    5. l - 2 so far\n",
        "    Returns \"goall\"\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    pattern = r\"\\n\\d+. ([a-z])\"\n",
        "    matches = re.findall(pattern, response, flags=re.IGNORECASE)\n",
        "    if matches:\n",
        "        return \"\".join([m for m in matches])\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "extract_spelling(\n",
        "    \"\"\"Here is a letter by letter spelling:\n",
        "\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "3. l - 2 so far\n",
        "5. l - 2 so far\n",
        "\"\"\"\n",
        ") == \"goall\"\n",
        "\n",
        "\n",
        "def spelling_reward_func(completions, words, **kwargs) -> list[float]:\n",
        "    \"\"\"A spelling reward function.\"\"\"\n",
        "    from collections import Counter\n",
        "\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    res = []\n",
        "\n",
        "    for word, response in zip(words, responses):\n",
        "        reward = 0.0\n",
        "\n",
        "        # Provide a reward for exactly correct spelling\n",
        "        reward += 1 if extract_spelling(response) == word else -1\n",
        "\n",
        "        # Provide a reward for each letter of difference in length\n",
        "        reward -= abs(len(word) - len(extract_spelling(response)))\n",
        "\n",
        "        # Provide a reward for each letter that is not in the target word\n",
        "        reward -= sum(1 for letter in extract_spelling(response) if letter not in word)\n",
        "\n",
        "        # Provide a reward for each letter that is in the target word but not in the response\n",
        "        reward -= sum(1 for letter in word if letter not in extract_spelling(response))\n",
        "\n",
        "        res.append(reward)\n",
        "    return res\n",
        "\n",
        "\n",
        "res = spelling_reward_func(\n",
        "    completions=[\n",
        "        [  # Worse response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. l - 2 so far\n",
        "5. l - 2 so far\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "        [  # Better Response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. l - 2 so far\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "    ],\n",
        "    words=[\"goal\", \"goal\"],\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Counting reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.6, 1.0]\n",
            "time: 42.2 ms (started: 2025-12-26 19:20:32 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Let's reward the model for properly counting the occurrences of a letter in a word\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "# No changes needed in this cell, but feel free to experiment with variations on the prompt\n",
        "\n",
        "\n",
        "def get_resp_letters_and_counts(response):\n",
        "    \"\"\"Extract the letters and counts from the response\n",
        "\n",
        "    Example:\n",
        "    1. g - 1 so far\n",
        "    2. o - 1 so far\n",
        "    3. a - 2 so far\n",
        "    4. a - 2 so far\n",
        "    5. l - 2 so far\n",
        "    returns [('g', 1), ('o', 1), ('a', 2), ('a', 2), ('l', 2)]\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    pattern = r\"\\n(\\d+)\\. ([a-z])\\D*(\\d+)\"\n",
        "\n",
        "    # Find strings matching e.g. \"2. a - 2 so far\"\n",
        "    matches = re.findall(pattern, response, flags=re.IGNORECASE)\n",
        "\n",
        "    if not matches:\n",
        "        return []\n",
        "\n",
        "    return [\n",
        "        (matched_letter, matched_count_so_far)\n",
        "        for _, matched_letter, matched_count_so_far in matches\n",
        "    ]\n",
        "\n",
        "\n",
        "assert get_resp_letters_and_counts(\n",
        "    \"\"\"\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. a - 2 so far\n",
        "5. l - 2 so far\n",
        "\"\"\"\n",
        ") == [(\"g\", \"1\"), (\"o\", \"1\"), (\"a\", \"2\"), (\"a\", \"2\"), (\"l\", \"2\")]\n",
        "\n",
        "\n",
        "def counting_reward_func(completions, letters, **kwargs) -> list[float]:\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    res = []\n",
        "\n",
        "    # Iterate over each of the letter-response pairs\n",
        "    for letter, response in zip(letters, responses):\n",
        "        reward = 0\n",
        "\n",
        "        letters_and_counts = get_resp_letters_and_counts(response)\n",
        "\n",
        "        # If there are no matches, provide a negative reward\n",
        "        if not letters_and_counts:\n",
        "            res.append(-1)\n",
        "            continue\n",
        "\n",
        "        # Start counting the matching letters\n",
        "        actual_count = 0\n",
        "        for resp_letter, resp_count in letters_and_counts:\n",
        "            # If there's a match, count the letter\n",
        "            if letter == resp_letter:\n",
        "                actual_count += 1\n",
        "\n",
        "            # If the count is accurate, add a reward, else subtract a reward\n",
        "            reward += 1 if actual_count == int(resp_count) else -1\n",
        "\n",
        "        # Return the reward normalized by the length of the matches\n",
        "        res.append(reward / len(letters_and_counts))\n",
        "    return res\n",
        "\n",
        "\n",
        "res = counting_reward_func(\n",
        "    completions=[\n",
        "        [  # Worse response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\\nHere is a letter by letter spelling:\n",
        "\n",
        "1. g - 0 so far\n",
        "2. o - 0 so far\n",
        "3. a - 1 so far\n",
        "4. a - 2 so far\n",
        "5. l - 0 so far\n",
        "\n",
        "\\n</reasoning>\\n<answer>\\nThis is my answer.\\n</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "        [  # Better response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\\nHere is a letter by letter spelling:\n",
        "\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 1 so far\n",
        "4. a - 1 so far\n",
        "5. l - 1 so far\n",
        "\n",
        "\\n</reasoning>\\n<answer>\\nThis is my answer.\\n</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "    ],\n",
        "    letters=[\"g\", \"g\"],\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Formatting reward functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-1.0, 1.0]\n",
            "time: 42.5 ms (started: 2025-12-26 19:20:32 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Reward the model for providing the response in a specific format\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "\n",
        "def extract_xml_answer(text: str) -> str:\n",
        "    \"\"\"Extracts the string between <answer> and </answer> tags.\"\"\"\n",
        "    import re\n",
        "\n",
        "    pattern = r\"<answer>(.*?)</answer>\"\n",
        "    match = re.search(pattern, text, re.DOTALL)\n",
        "    if match:\n",
        "        return match.group(1).strip()\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "assert (\n",
        "    extract_xml_answer(\"\"\"\n",
        "<reasoning>\n",
        "This is my reasoning.\n",
        "</reasoning>\n",
        "<answer>SUPERCALIFRAGILISTICEXPIALIDOCIOUS</answer>\n",
        "\"\"\")\n",
        "    == \"SUPERCALIFRAGILISTICEXPIALIDOCIOUS\"\n",
        ")\n",
        "\n",
        "\n",
        "def format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    pattern = r\"\\s*<reasoning>.*?</reasoning>\\s*<answer>.*?</answer>\"\n",
        "\n",
        "    res = []\n",
        "\n",
        "    for completion in completions:\n",
        "        reward = 0.0\n",
        "\n",
        "        # Extract the response content\n",
        "        response = completion[0][\"content\"]\n",
        "\n",
        "        # Check if the response matches the pattern\n",
        "        match = re.match(pattern, response, flags=re.MULTILINE | re.DOTALL)\n",
        "\n",
        "        # If it matches, return 0.5, otherwise return 0.0\n",
        "        if match:\n",
        "            reward += 0.5  \n",
        "        else:\n",
        "            reward -= 0.5\n",
        "        # Extract the answer from the response\n",
        "        # extracted_answer = **********\n",
        "        # If the answer is an integer, add 0.5 to the reward\n",
        "        # if ... **********\n",
        "        if extract_xml_answer(response).isdigit():\n",
        "            reward += 0.5\n",
        "        else:\n",
        "            reward -= 0.5\n",
        "            \n",
        "        res.append(reward)\n",
        "    return res\n",
        "\n",
        "\n",
        "res = format_reward_func(\n",
        "    completions=[\n",
        "        [{\"content\": \"This is my answer\"}],\n",
        "        [\n",
        "            {\n",
        "                \"content\": \"<reasoning>\\nThis is my reasoning.\\n</reasoning>\\n<answer>\\n3\\n</answer>\"\n",
        "            }\n",
        "        ],\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task correctness reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many...\n",
            "Answer: 0\n",
            "Response: <reasoning>.../reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "[-1, 1]\n",
            "time: 50.3 ms (started: 2025-12-26 19:20:32 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Reward the model for providing the correct answer\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "\n",
        "def correct_answer_reward_func(prompts, completions, counts, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward the final answer if it is correct.\"\"\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
        "\n",
        "    # Print a nice summary of the first prompt, answer, and response to see while training\n",
        "    print(f\"\"\"\n",
        "{\"-\" * 20}\n",
        "Question: {prompts[0][-1][\"content\"]}\n",
        "Answer: {counts[0]}\n",
        "Response: {responses[0]}\n",
        "Extracted: {extracted_responses[0]}\n",
        "Correct: {str(extracted_responses[0]) == str(counts[0])}!\n",
        "    \"\"\")\n",
        "\n",
        "    res = [\n",
        "        # Provide reward for exactly correct answer\n",
        "        1 if str(r) == str(a) else -1\n",
        "        for r, a in zip(extracted_responses, counts)\n",
        "    ]\n",
        "    return res\n",
        "\n",
        "\n",
        "res = correct_answer_reward_func(\n",
        "    prompts=[\n",
        "        [{\"content\": \"\"\"How many...\"\"\"}],\n",
        "        [{\"content\": \"\"\"How many...\"\"\"}],\n",
        "    ],\n",
        "    completions=[\n",
        "        [{\"content\": \"\"\"<reasoning>.../reasoning>\\n<answer>\\n3\\n</answer>\"\"\"}],\n",
        "        [{\"content\": \"\"\"<reasoning>.../reasoning>\\n<answer>\\n3\\n</answer>\"\"\"}],\n",
        "    ],\n",
        "    letters=[\"g\", \"g\"],\n",
        "    counts=[0, 3],\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### List the reward functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 47 ms (started: 2025-12-26 19:20:32 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# List out the reward functions we will use\n",
        "# No changes needed in this cell\n",
        "\n",
        "REWARD_FUNCS = [\n",
        "    numbering_reward_func,\n",
        "    spelling_reward_func,\n",
        "    counting_reward_func,\n",
        "    format_reward_func,\n",
        "    correct_answer_reward_func,\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the model\n",
        "\n",
        "Now set up GRPO Trainer and configurations!\n",
        "\n",
        "As you run the trainer, the goal is to see the various `reward` columns increase.\n",
        "\n",
        "After 50 steps or more, you may notice some of the reward standard deviations begin to decrease, meaning that the different predictions are starting to converge on solutions that give similar rewards. If your model has learned the task, then you'll see the `correct_answer_reward_function` increase to its highest value (check the function to see what that is).\n",
        "\n",
        "Here is an example, which successfully converged on a higher reward. Note, the values you see here will probably be different from yours, especially if your reward amounts are different.\n",
        "\n",
        "| Step | Training Loss | reward   | reward_std | ... | kl      | rewards / correct_answer_reward_function / mean | rewards / correct_answer_reward_function / std |\n",
        "|------|---------------|----------|------------|-----|---------|------------------------------------------|-----------------------------------------|\n",
        "| 1    | 0.000000      | 7.961805 | 2.368493   | ... | 0.020369| 0.875000                                 | 1.024695                                |\n",
        "| 2    | 0.000000      | 7.937500 | 1.352467   | ... | 0.016483| 0.875000                                 | 1.024695                                |\n",
        "| 3    | 0.000000      | 1.894792 | 6.462189   | ... | 0.013677| 0.375000                                 | 0.806226                                |\n",
        "| ...  | ...           | ...      | ...        | ... | ...     | ...                                      | ...                                     |\n",
        "| 398  | 0.000100      | 13.000000| 0.000000   | ... | 0.088529| 2.000000                                 | 0.000000                                |\n",
        "| 399  | 0.000100      | 13.000000| 0.000000   | ... | 0.088617| 2.000000                                 | 0.000000                                |\n",
        "| 400  | 0.000100      | 13.000000| 0.000000   | ... | 0.096202| 2.000000                                 | 0.000000                                |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 50.8 ms (started: 2025-12-26 19:20:32 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Fill in the GRPO Parameters we'll use throughout this project\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "# Read about the GRPO params here https://huggingface.co/docs/trl/main/en/grpo_trainer\n",
        "COMMON_GRPO_TRAINING_PARAMS = dict(\n",
        "    # Set appropriate values for `learning_rate` and `beta`\n",
        "    # See: https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/lora-hyperparameters-guide\n",
        "    # See: https://huggingface.co/docs/trl/main/en/grpo_trainer\n",
        "    learning_rate=0.0002,\n",
        "    beta=0.0002,\n",
        "    # Set the batch size appropriately for your hardware. For GRPO there are a number of parameters to set.\n",
        "    # If you are not sure about your GPU, assume you have a T4. See the memory specs here:\n",
        "    # https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-product-literature/T4%20Product%20Brief.pdf\n",
        "    per_device_train_batch_size=16,  # per_device_train_batch_size / num_generations determines the number of simultaneous prompts to consider.\n",
        "    # Note: Set per_device_train_batch_size to at most 16 on the Vocareum T4 for best stability\n",
        "    num_generations=16,\n",
        "    gradient_accumulation_steps=8,\n",
        "    adam_beta1=0.9,\n",
        "    adam_beta2=0.99,\n",
        "    weight_decay=0.1,\n",
        "    warmup_ratio=0.1,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    optim=\"adamw_8bit\",\n",
        "    logging_steps=1,\n",
        "    max_prompt_length=256,\n",
        "    max_completion_length=200,\n",
        "    num_train_epochs=1,  # Set to 1 for a full training run\n",
        "    save_steps=250,\n",
        "    max_grad_norm=0.1,\n",
        "    report_to=\"none\",  # Setting this value lets us use Weights and Biases\n",
        "    output_dir=\"outputs\",\n",
        "    use_vllm=True,  # vll speeds up inference! See https://github.com/vllm-project/vllm\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quick train\n",
        "\n",
        "Let's train the model for just 5 steps (`max_steps=5`). As it runs we can double check we've set up our prompts correctly before running for a longer amount of time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 401 | Num Epochs = 1 | Total steps = 5\n",
            "O^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 8\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 8 x 1) = 128\n",
            " \"-____-\"     Trainable parameters = 29,933,568 of 3,115,872,256 (0.96% trained)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"glisten\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of g's in the word glisten\n",
            "1. g - 1 so far\n",
            "2. l - 0 so far (no additional g's)\n",
            "3. i - 0 so far (no additional g's)\n",
            "4. t - 0 so far (no additional g's)\n",
            "5. n - 0 so far (no additional g's)\n",
            "6. s - 0 so far (no additional g's)\n",
            "The count of letter \"g\" in the word \"glisten\" is 1.\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 04:19, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completions / mean_length</th>\n",
              "      <th>completions / min_length</th>\n",
              "      <th>completions / max_length</th>\n",
              "      <th>completions / clipped_ratio</th>\n",
              "      <th>completions / mean_terminated_length</th>\n",
              "      <th>completions / min_terminated_length</th>\n",
              "      <th>completions / max_terminated_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / numbering_reward_func / mean</th>\n",
              "      <th>rewards / numbering_reward_func / std</th>\n",
              "      <th>rewards / spelling_reward_func / mean</th>\n",
              "      <th>rewards / spelling_reward_func / std</th>\n",
              "      <th>rewards / counting_reward_func / mean</th>\n",
              "      <th>rewards / counting_reward_func / std</th>\n",
              "      <th>rewards / format_reward_func / mean</th>\n",
              "      <th>rewards / format_reward_func / std</th>\n",
              "      <th>rewards / correct_answer_reward_func / mean</th>\n",
              "      <th>rewards / correct_answer_reward_func / std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.175412</td>\n",
              "      <td>1.787882</td>\n",
              "      <td>79.437500</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>164.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.437500</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>164.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.907729</td>\n",
              "      <td>0.206731</td>\n",
              "      <td>-2.125000</td>\n",
              "      <td>2.574863</td>\n",
              "      <td>0.002059</td>\n",
              "      <td>0.610379</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.390625</td>\n",
              "      <td>0.924167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.361117</td>\n",
              "      <td>2.463119</td>\n",
              "      <td>83.828125</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>82.913383</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.911272</td>\n",
              "      <td>0.227604</td>\n",
              "      <td>-2.109375</td>\n",
              "      <td>3.405032</td>\n",
              "      <td>0.133860</td>\n",
              "      <td>0.732913</td>\n",
              "      <td>0.984375</td>\n",
              "      <td>0.176777</td>\n",
              "      <td>-0.281250</td>\n",
              "      <td>0.963405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.809747</td>\n",
              "      <td>1.473810</td>\n",
              "      <td>94.429688</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>139.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.429688</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>139.000000</td>\n",
              "      <td>0.075738</td>\n",
              "      <td>0.966797</td>\n",
              "      <td>0.175719</td>\n",
              "      <td>-0.632812</td>\n",
              "      <td>2.011272</td>\n",
              "      <td>0.225763</td>\n",
              "      <td>0.485766</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.972050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>1.156932</td>\n",
              "      <td>1.731458</td>\n",
              "      <td>96.554688</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>96.554688</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>0.099853</td>\n",
              "      <td>0.948661</td>\n",
              "      <td>0.089159</td>\n",
              "      <td>-1.656250</td>\n",
              "      <td>1.807410</td>\n",
              "      <td>0.614521</td>\n",
              "      <td>0.408094</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.972050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>1.910094</td>\n",
              "      <td>1.112657</td>\n",
              "      <td>97.398438</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>96.590553</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>148.000000</td>\n",
              "      <td>0.127033</td>\n",
              "      <td>0.953497</td>\n",
              "      <td>0.088477</td>\n",
              "      <td>-0.953125</td>\n",
              "      <td>1.852257</td>\n",
              "      <td>0.300347</td>\n",
              "      <td>0.619589</td>\n",
              "      <td>0.984375</td>\n",
              "      <td>0.176777</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.783692</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"absolve\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of t's in the word absolve\n",
            "1. a - 0 so far\n",
            "2. b - 0 so far\n",
            "3. s - 0 so far\n",
            "4. s - 1 so far\n",
            "5. o - 1 so far\n",
            "6. v - 1 so far\n",
            "7. e - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"crave\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"r\" in the word \"crave\"\n",
            "1. c - 0 so far\n",
            "2. r - 1 so far\n",
            "3. a - 1 so far\n",
            "4. v - 1 so far\n",
            "5. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"v\" are there in the word \"absolve\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"v\" in the word \"absolve\"\n",
            "1. a - 0 so far\n",
            "2. b - 0 so far\n",
            "3. s - 0 so far\n",
            "4. o - 0 so far\n",
            "5. l - 0 so far\n",
            "6. e - 0 so far\n",
            "There are no \"v\"s in the word \"absolve\".  \n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"echo\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"e\" in the word \"echo\"\n",
            "1. e - 1 so far\n",
            "2. ch - 0 so far\n",
            "3. o - 0 so far\n",
            "4. c - 0 so far\n",
            "5. h - 0 so far\n",
            "The letter \"e\" appears 1 time in the word \"echo\".\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "time: 5min 58s (started: 2025-12-26 19:20:32 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Train for just a few steps for a few minutes\n",
        "# This will allow us to observe the results and make any changes to our reward functions\n",
        "# before starting a longer run. Note, you won't see much change in the average.\n",
        "# reward values\n",
        "# No changes are needed here\n",
        "\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "\n",
        "# Short train to check on reward functions\n",
        "training_args = GRPOConfig(\n",
        "    **COMMON_GRPO_TRAINING_PARAMS,\n",
        "    # We'll just run for a modest 5 steps to make sure everything works and to\n",
        "    # estimate the amount of time it will take to run the full training.\n",
        "    max_steps=5,\n",
        ")\n",
        "trainer = GRPOTrainer(\n",
        "    model=model,\n",
        "    processing_class=tokenizer,\n",
        "    reward_funcs=REWARD_FUNCS,\n",
        "    args=training_args,\n",
        "    train_dataset=ds,\n",
        ")\n",
        "trainer_res = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "available columns: dict_keys(['loss', 'grad_norm', 'learning_rate', 'num_tokens', 'completions/mean_length', 'completions/min_length', 'completions/max_length', 'completions/clipped_ratio', 'completions/mean_terminated_length', 'completions/min_terminated_length', 'completions/max_terminated_length', 'rewards/numbering_reward_func/mean', 'rewards/numbering_reward_func/std', 'rewards/spelling_reward_func/mean', 'rewards/spelling_reward_func/std', 'rewards/counting_reward_func/mean', 'rewards/counting_reward_func/std', 'rewards/format_reward_func/mean', 'rewards/format_reward_func/std', 'rewards/correct_answer_reward_func/mean', 'rewards/correct_answer_reward_func/std', 'reward', 'reward_std', 'frac_reward_zero_std', 'completion_length', 'kl', 'epoch', 'step'])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 2.43 s (started: 2025-12-26 19:26:31 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Show the total (sum) of the rewards as well as the correct_answer_reward_func (means with in the batch)\n",
        "# No changes needed in this cell\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# If you want to graph other columns, check these out\n",
        "print(f\"available columns: {trainer.state.log_history[0].keys()}\")\n",
        "\n",
        "log_df = pd.DataFrame(trainer.state.log_history)\n",
        "log_df[\"reward\"].plot()\n",
        "log_df[\"rewards/correct_answer_reward_func/mean\"].plot()\n",
        "\n",
        "# Show the legend\n",
        "plt.legend([\"reward\", \"rewards/correct_answer_reward_func/mean\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Slower train (1+ hour)\n",
        "\n",
        "If everything looks good, let's go for a longer training session!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 401 | Num Epochs = 1 | Total steps = 50\n",
            "O^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 8\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 8 x 1) = 128\n",
            " \"-____-\"     Trainable parameters = 29,933,568 of 3,115,872,256 (0.96% trained)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"glisten\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"g\"s in the word \"glisten\"\n",
            "1. g - 1 so far\n",
            "2. l - 1 so far\n",
            "3. i - 1 so far\n",
            "4. s - 1 so far\n",
            "5. t - 1 so far\n",
            "6. e - 1 so far\n",
            "7. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 38:29, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completions / mean_length</th>\n",
              "      <th>completions / min_length</th>\n",
              "      <th>completions / max_length</th>\n",
              "      <th>completions / clipped_ratio</th>\n",
              "      <th>completions / mean_terminated_length</th>\n",
              "      <th>completions / min_terminated_length</th>\n",
              "      <th>completions / max_terminated_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / numbering_reward_func / mean</th>\n",
              "      <th>rewards / numbering_reward_func / std</th>\n",
              "      <th>rewards / spelling_reward_func / mean</th>\n",
              "      <th>rewards / spelling_reward_func / std</th>\n",
              "      <th>rewards / counting_reward_func / mean</th>\n",
              "      <th>rewards / counting_reward_func / std</th>\n",
              "      <th>rewards / format_reward_func / mean</th>\n",
              "      <th>rewards / format_reward_func / std</th>\n",
              "      <th>rewards / correct_answer_reward_func / mean</th>\n",
              "      <th>rewards / correct_answer_reward_func / std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>4.546875</td>\n",
              "      <td>0.100778</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.147705</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.546875</td>\n",
              "      <td>0.840504</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>4.381511</td>\n",
              "      <td>0.152571</td>\n",
              "      <td>85.664062</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.664062</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.106281</td>\n",
              "      <td>0.996094</td>\n",
              "      <td>0.044194</td>\n",
              "      <td>0.421875</td>\n",
              "      <td>0.935809</td>\n",
              "      <td>0.963542</td>\n",
              "      <td>0.104445</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.375000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.375000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.091127</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>4.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.921875</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.921875</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>0.101977</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.972050</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>4.651042</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>80.171875</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80.171875</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>0.097556</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.984375</td>\n",
              "      <td>0.176777</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.221346</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.664037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>2.903646</td>\n",
              "      <td>0.486574</td>\n",
              "      <td>84.109375</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>115.000000</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>83.866142</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>115.000000</td>\n",
              "      <td>0.497598</td>\n",
              "      <td>0.882812</td>\n",
              "      <td>0.328947</td>\n",
              "      <td>-0.375000</td>\n",
              "      <td>2.534797</td>\n",
              "      <td>0.856771</td>\n",
              "      <td>0.503155</td>\n",
              "      <td>0.773438</td>\n",
              "      <td>0.617524</td>\n",
              "      <td>0.765625</td>\n",
              "      <td>0.645815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>4.393973</td>\n",
              "      <td>0.268562</td>\n",
              "      <td>79.812500</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.812500</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.094909</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.398438</td>\n",
              "      <td>0.982844</td>\n",
              "      <td>0.995536</td>\n",
              "      <td>0.035573</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>4.429688</td>\n",
              "      <td>0.246020</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.110791</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.429688</td>\n",
              "      <td>0.919462</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>3.713542</td>\n",
              "      <td>0.398979</td>\n",
              "      <td>89.742188</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>89.742188</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.116781</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>1.609500</td>\n",
              "      <td>0.955729</td>\n",
              "      <td>0.113568</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.664037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>4.202232</td>\n",
              "      <td>0.652118</td>\n",
              "      <td>82.578125</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.578125</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.127120</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>1.094007</td>\n",
              "      <td>0.936607</td>\n",
              "      <td>0.141293</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.640625</td>\n",
              "      <td>0.770871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>4.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.125000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.125000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.066277</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.664037</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>3.422712</td>\n",
              "      <td>0.488738</td>\n",
              "      <td>85.875000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.875000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.190717</td>\n",
              "      <td>0.968750</td>\n",
              "      <td>0.060753</td>\n",
              "      <td>-0.453125</td>\n",
              "      <td>1.571695</td>\n",
              "      <td>0.985212</td>\n",
              "      <td>0.061863</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.921875</td>\n",
              "      <td>0.389010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>2.763765</td>\n",
              "      <td>0.688570</td>\n",
              "      <td>86.257812</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86.257812</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>0.199177</td>\n",
              "      <td>0.928944</td>\n",
              "      <td>0.083296</td>\n",
              "      <td>-0.890625</td>\n",
              "      <td>1.828189</td>\n",
              "      <td>0.959821</td>\n",
              "      <td>0.117472</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.765625</td>\n",
              "      <td>0.645815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>4.285268</td>\n",
              "      <td>0.292548</td>\n",
              "      <td>84.351562</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>84.351562</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.127306</td>\n",
              "      <td>0.991741</td>\n",
              "      <td>0.034790</td>\n",
              "      <td>0.664062</td>\n",
              "      <td>0.889814</td>\n",
              "      <td>0.863839</td>\n",
              "      <td>0.369085</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.765625</td>\n",
              "      <td>0.645815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>3.783296</td>\n",
              "      <td>0.473958</td>\n",
              "      <td>79.835938</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.835938</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>0.183921</td>\n",
              "      <td>0.973028</td>\n",
              "      <td>0.058043</td>\n",
              "      <td>-0.156250</td>\n",
              "      <td>1.444171</td>\n",
              "      <td>0.997768</td>\n",
              "      <td>0.025254</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.968750</td>\n",
              "      <td>0.249014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>3.935082</td>\n",
              "      <td>0.376526</td>\n",
              "      <td>81.796875</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.796875</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.951625</td>\n",
              "      <td>0.998698</td>\n",
              "      <td>0.014731</td>\n",
              "      <td>0.257812</td>\n",
              "      <td>1.095776</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.189725</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.664037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>3.201389</td>\n",
              "      <td>0.505238</td>\n",
              "      <td>86.781250</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86.781250</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>0.121377</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.781250</td>\n",
              "      <td>1.882106</td>\n",
              "      <td>0.982639</td>\n",
              "      <td>0.079902</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>2.849479</td>\n",
              "      <td>0.764837</td>\n",
              "      <td>81.015625</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.015625</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>0.160275</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.046875</td>\n",
              "      <td>1.606382</td>\n",
              "      <td>0.896354</td>\n",
              "      <td>0.173444</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>3.230041</td>\n",
              "      <td>0.575436</td>\n",
              "      <td>92.218750</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>92.218750</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>0.173938</td>\n",
              "      <td>0.995536</td>\n",
              "      <td>0.050508</td>\n",
              "      <td>-0.710938</td>\n",
              "      <td>1.757559</td>\n",
              "      <td>0.961068</td>\n",
              "      <td>0.202974</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.984375</td>\n",
              "      <td>0.176777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>4.367188</td>\n",
              "      <td>0.175389</td>\n",
              "      <td>87.414062</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.414062</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.120294</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.367188</td>\n",
              "      <td>1.114479</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.003600</td>\n",
              "      <td>2.542969</td>\n",
              "      <td>0.749721</td>\n",
              "      <td>84.703125</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>83.795273</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>2.269183</td>\n",
              "      <td>0.847656</td>\n",
              "      <td>0.511900</td>\n",
              "      <td>-0.601562</td>\n",
              "      <td>3.442074</td>\n",
              "      <td>0.796875</td>\n",
              "      <td>0.575429</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.664037</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.664037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>4.080729</td>\n",
              "      <td>0.337876</td>\n",
              "      <td>88.312500</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>88.312500</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.150911</td>\n",
              "      <td>0.998047</td>\n",
              "      <td>0.022097</td>\n",
              "      <td>0.421875</td>\n",
              "      <td>1.016474</td>\n",
              "      <td>0.957682</td>\n",
              "      <td>0.133921</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.703125</td>\n",
              "      <td>0.713860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>3.329753</td>\n",
              "      <td>0.301647</td>\n",
              "      <td>87.085938</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.085938</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.154165</td>\n",
              "      <td>0.983398</td>\n",
              "      <td>0.045771</td>\n",
              "      <td>0.148438</td>\n",
              "      <td>1.177812</td>\n",
              "      <td>0.854167</td>\n",
              "      <td>0.291465</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.343750</td>\n",
              "      <td>0.942751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>4.106771</td>\n",
              "      <td>0.218353</td>\n",
              "      <td>87.125000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.125000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.149080</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.453125</td>\n",
              "      <td>0.894950</td>\n",
              "      <td>0.950521</td>\n",
              "      <td>0.118977</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.703125</td>\n",
              "      <td>0.713860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>3.589509</td>\n",
              "      <td>0.397877</td>\n",
              "      <td>81.828125</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.828125</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.186802</td>\n",
              "      <td>0.983259</td>\n",
              "      <td>0.050029</td>\n",
              "      <td>0.281250</td>\n",
              "      <td>1.321759</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.339523</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.869428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>4.531250</td>\n",
              "      <td>0.085391</td>\n",
              "      <td>90.375000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>90.375000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.159235</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.531250</td>\n",
              "      <td>0.850544</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.001100</td>\n",
              "      <td>2.767578</td>\n",
              "      <td>0.374032</td>\n",
              "      <td>84.234375</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>84.234375</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.661539</td>\n",
              "      <td>0.798828</td>\n",
              "      <td>0.552427</td>\n",
              "      <td>-0.109375</td>\n",
              "      <td>2.848495</td>\n",
              "      <td>0.742188</td>\n",
              "      <td>0.555092</td>\n",
              "      <td>0.820312</td>\n",
              "      <td>0.538788</td>\n",
              "      <td>0.515625</td>\n",
              "      <td>0.860181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>4.714286</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.375000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.375000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.151589</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.964286</td>\n",
              "      <td>0.094862</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.664037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86.125000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86.125000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.080412</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.869428</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>4.958333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>82.296875</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.296875</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.100026</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.960938</td>\n",
              "      <td>0.317528</td>\n",
              "      <td>0.997396</td>\n",
              "      <td>0.029463</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>4.584822</td>\n",
              "      <td>0.226301</td>\n",
              "      <td>87.382812</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.382812</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.091762</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.609375</td>\n",
              "      <td>0.795998</td>\n",
              "      <td>0.991071</td>\n",
              "      <td>0.101015</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.984375</td>\n",
              "      <td>0.176777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>4.926339</td>\n",
              "      <td>0.158366</td>\n",
              "      <td>86.859375</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86.859375</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.119514</td>\n",
              "      <td>0.996652</td>\n",
              "      <td>0.021698</td>\n",
              "      <td>0.929688</td>\n",
              "      <td>0.455649</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>4.677567</td>\n",
              "      <td>0.146875</td>\n",
              "      <td>86.117188</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86.117188</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.112618</td>\n",
              "      <td>0.998438</td>\n",
              "      <td>0.017678</td>\n",
              "      <td>0.968750</td>\n",
              "      <td>0.353553</td>\n",
              "      <td>0.960379</td>\n",
              "      <td>0.103299</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.664037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>87.351562</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.351562</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.140203</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.609375</td>\n",
              "      <td>0.880536</td>\n",
              "      <td>0.984375</td>\n",
              "      <td>0.070734</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.906250</td>\n",
              "      <td>0.424403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>4.741072</td>\n",
              "      <td>0.267420</td>\n",
              "      <td>77.562500</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>77.562500</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.182817</td>\n",
              "      <td>0.991071</td>\n",
              "      <td>0.034716</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.972050</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>4.358259</td>\n",
              "      <td>0.128751</td>\n",
              "      <td>83.492188</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>83.492188</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.207851</td>\n",
              "      <td>0.998884</td>\n",
              "      <td>0.012627</td>\n",
              "      <td>0.359375</td>\n",
              "      <td>1.099280</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>3.904204</td>\n",
              "      <td>0.194418</td>\n",
              "      <td>85.828125</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.828125</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.291563</td>\n",
              "      <td>0.996652</td>\n",
              "      <td>0.037881</td>\n",
              "      <td>0.210938</td>\n",
              "      <td>1.047324</td>\n",
              "      <td>0.962240</td>\n",
              "      <td>0.091083</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.734375</td>\n",
              "      <td>0.681411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>4.640625</td>\n",
              "      <td>0.272907</td>\n",
              "      <td>81.335938</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.335938</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.273438</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.640625</td>\n",
              "      <td>0.839332</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>4.130859</td>\n",
              "      <td>0.134061</td>\n",
              "      <td>86.875000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86.875000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.199804</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.460938</td>\n",
              "      <td>0.904079</td>\n",
              "      <td>0.919922</td>\n",
              "      <td>0.151041</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.664037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.001800</td>\n",
              "      <td>2.315383</td>\n",
              "      <td>0.545137</td>\n",
              "      <td>88.640625</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>88.640625</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>1.154123</td>\n",
              "      <td>0.891462</td>\n",
              "      <td>0.295543</td>\n",
              "      <td>-0.562500</td>\n",
              "      <td>2.757238</td>\n",
              "      <td>0.736421</td>\n",
              "      <td>0.585954</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.664037</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.869428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>4.390625</td>\n",
              "      <td>0.128087</td>\n",
              "      <td>82.875000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.875000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.223900</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.640625</td>\n",
              "      <td>0.770871</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.664037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>3.880804</td>\n",
              "      <td>0.272130</td>\n",
              "      <td>89.429688</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>89.429688</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>0.220054</td>\n",
              "      <td>0.983259</td>\n",
              "      <td>0.046130</td>\n",
              "      <td>0.148438</td>\n",
              "      <td>1.157583</td>\n",
              "      <td>0.874107</td>\n",
              "      <td>0.298379</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.486025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>4.468750</td>\n",
              "      <td>0.085391</td>\n",
              "      <td>87.203125</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.203125</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.224625</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.468750</td>\n",
              "      <td>0.886802</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>4.648438</td>\n",
              "      <td>0.107998</td>\n",
              "      <td>88.453125</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>88.314957</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>0.208107</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.742188</td>\n",
              "      <td>0.690157</td>\n",
              "      <td>0.906250</td>\n",
              "      <td>0.251262</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>3.807143</td>\n",
              "      <td>0.298142</td>\n",
              "      <td>78.687500</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>78.687500</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>0.201835</td>\n",
              "      <td>0.982143</td>\n",
              "      <td>0.047431</td>\n",
              "      <td>0.343750</td>\n",
              "      <td>1.245069</td>\n",
              "      <td>0.918750</td>\n",
              "      <td>0.154928</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.830046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.007300</td>\n",
              "      <td>2.680525</td>\n",
              "      <td>0.221753</td>\n",
              "      <td>77.070312</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>77.070312</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>4.578475</td>\n",
              "      <td>0.892578</td>\n",
              "      <td>0.295444</td>\n",
              "      <td>-0.148438</td>\n",
              "      <td>3.074123</td>\n",
              "      <td>0.686384</td>\n",
              "      <td>0.596149</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.664037</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.869428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>4.842187</td>\n",
              "      <td>0.324576</td>\n",
              "      <td>83.179688</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>83.179688</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.196722</td>\n",
              "      <td>0.998438</td>\n",
              "      <td>0.017678</td>\n",
              "      <td>0.859375</td>\n",
              "      <td>0.571424</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.984375</td>\n",
              "      <td>0.176777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>4.453125</td>\n",
              "      <td>0.085898</td>\n",
              "      <td>83.437500</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>83.437500</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.217560</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.468750</td>\n",
              "      <td>0.938566</td>\n",
              "      <td>0.984375</td>\n",
              "      <td>0.101255</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>3.495536</td>\n",
              "      <td>0.295468</td>\n",
              "      <td>86.054688</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86.054688</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.262028</td>\n",
              "      <td>0.983259</td>\n",
              "      <td>0.046130</td>\n",
              "      <td>0.039062</td>\n",
              "      <td>1.206298</td>\n",
              "      <td>0.957589</td>\n",
              "      <td>0.119401</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.515625</td>\n",
              "      <td>0.860181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>3.057292</td>\n",
              "      <td>0.293715</td>\n",
              "      <td>91.359375</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>91.359375</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.288576</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.195312</td>\n",
              "      <td>0.996518</td>\n",
              "      <td>0.955729</td>\n",
              "      <td>0.142818</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.296875</td>\n",
              "      <td>0.958668</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"absolve\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of \"t\"s in the word \"absolve\"\n",
            "1. a - 0 so far\n",
            "2. b - 0 so far\n",
            "3. s - 0 so far\n",
            "4. l - 0 so far\n",
            "5. o - 0 so far\n",
            "6. v - 0 so far\n",
            "7. e - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"crave\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"r\"s in the word \"crave\"\n",
            "1. c - 0 so far\n",
            "2. r - 1 so far\n",
            "3. a - 1 so far\n",
            "4. v - 1 so far\n",
            "5. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"v\" are there in the word \"absolve\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"v\"s in the word \"absolve\"\n",
            "1. a - 0 so far\n",
            "2. b - 0 so far\n",
            "3. s - 0 so far\n",
            "4. l - 0 so far\n",
            "5. o - 0 so far\n",
            "6. v - 1 so far\n",
            "7. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"echo\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"e\"s in the word \"echo\"\n",
            "1. e - 1 so far\n",
            "2. c - 1 so far\n",
            "3. h - 1 so far\n",
            "4. o - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"o\" are there in the word \"ivory\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"o\"s in the word \"ivory\"\n",
            "1. i - 0 so far\n",
            "2. v - 0 so far\n",
            "3. o - 1 so far\n",
            "4. r - 1 so far\n",
            "5. y - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"fume\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"m\"s in the word \"fume\"\n",
            "1. f - 0 so far\n",
            "2. u - 0 so far\n",
            "3. m - 1 so far\n",
            "4. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"f\" are there in the word \"frescos\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"f\"s in the word \"frescos\"\n",
            "1. f - 1 so far\n",
            "2. r - 1 so far\n",
            "3. e - 1 so far\n",
            "4. s - 1 so far\n",
            "5. c - 1 so far\n",
            "6. o - 1 so far\n",
            "7. s - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"capture\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of \"n\"s in the word \"capture\"\n",
            "1. c - 0 so far\n",
            "2. a - 0 so far\n",
            "3. p - 0 so far\n",
            "4. t - 0 so far\n",
            "5. u - 0 so far\n",
            "6. r - 0 so far\n",
            "7. e - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"k\" are there in the word \"knack\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "Counting the number of \"k\"s in the word \"knack\"\n",
            "1. k - 1 so far\n",
            "2. n - 1 so far\n",
            "3. a - 1 so far\n",
            "4. c - 1 so far\n",
            "5. k - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"b\" are there in the word \"zealous\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of \"b\"s in the word \"zealous\"\n",
            "1. z - 0 so far\n",
            "2. e - 0 so far\n",
            "3. a - 0 so far\n",
            "4. l - 0 so far\n",
            "5. o - 0 so far\n",
            "6. u - 0 so far\n",
            "7. s - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"tavern\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"t\"s in the word \"tavern\"\n",
            "1. t - 1 so far\n",
            "2. a - 1 so far\n",
            "3. v - 1 so far\n",
            "4. e - 1 so far\n",
            "5. r - 1 so far\n",
            "6. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"a\"s in the word \"mantle\"\n",
            "1. m - 0 so far\n",
            "2. a - 1 so far\n",
            "3. n - 1 so far\n",
            "4. t - 1 so far\n",
            "5. l - 1 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"b\" are there in the word \"torrent\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of \"b\"s in the word \"torrent\"\n",
            "1. t - 0 so far\n",
            "2. o - 0 so far\n",
            "3. r - 0 so far\n",
            "4. e - 0 so far\n",
            "5. n - 0 so far\n",
            "6. t - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"fathom\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"m\"s in the word \"fathom\"\n",
            "1. f - 0 so far\n",
            "2. a - 0 so far\n",
            "3. h - 0 so far\n",
            "4. m - 1 so far\n",
            "5. a - 1 so far\n",
            "6. t - 1 so far\n",
            "7. h - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"enchant\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "Counting the number of \"n\"s in the word \"enchant\"\n",
            "1. e - 0 so far\n",
            "2. n - 1 so far\n",
            "3. c - 1 so far\n",
            "4. h - 1 so far\n",
            "5. a - 1 so far\n",
            "6. n - 1 so far\n",
            "7. t - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"fusion\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"n\"s in the word \"fusion\"\n",
            "1. f - 0 so far\n",
            "2. u - 0 so far\n",
            "3. s - 0 so far\n",
            "4. i - 0 so far\n",
            "5. n - 1 so far\n",
            "6. u - 1 so far\n",
            "7. r - 1 so far\n",
            "8. s - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"onset\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"t\"s in the word \"onset\"\n",
            "1. o - 0 so far\n",
            "2. n - 0 so far\n",
            "3. s - 0 so far\n",
            "4. e - 0 so far\n",
            "5. t - 1 so far\n",
            "6. s - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"y\" are there in the word \"ivory\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"y\"s in the word \"ivory\"\n",
            "1. i - 0 so far\n",
            "2. v - 0 so far\n",
            "3. o - 0 so far\n",
            "4. r - 0 so far\n",
            "5. y - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"whistle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"e\"s in the word \"whistle\"\n",
            "1. w - 0 so far\n",
            "2. h - 0 so far\n",
            "3. i - 0 so far\n",
            "4. s - 0 so far\n",
            "5. t - 0 so far\n",
            "6. l - 0 so far\n",
            "7. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"mirage\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"i\"s in the word \"mirage\"\n",
            "1. m - 0 so far\n",
            "2. i - 1 so far\n",
            "3. r - 1 so far\n",
            "4. a - 1 so far\n",
            "5. g - 1 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"sapphire\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"i\"s in the word \"sapphire\"\n",
            "1. s - 0 so far\n",
            "2. a - 0 so far\n",
            "3. p - 0 so far\n",
            "4. h - 0 so far\n",
            "5. a - 0 so far\n",
            "6. r - 0 so far\n",
            "7. e - 0 so far\n",
            "8. p - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"sapphire\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "Counting the number of \"p\"s in the word \"sapphire\"\n",
            "1. s - 0 so far\n",
            "2. a - 0 so far\n",
            "3. p - 1 so far\n",
            "4. h - 1 so far\n",
            "5. i - 1 so far\n",
            "6. a - 1 so far\n",
            "7. r - 1 so far\n",
            "8. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"triumph\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"i\"s in the word \"triumph\"\n",
            "1. t - 0 so far\n",
            "2. r - 0 so far\n",
            "3. i - 1 so far\n",
            "4. u - 1 so far\n",
            "5. m - 1 so far\n",
            "6. p - 1 so far\n",
            "7. h - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"verge\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "Counting the number of \"e\"s in the word \"verge\"\n",
            "1. v - 0 so far\n",
            "2. e - 1 so far\n",
            "3. r - 1 so far\n",
            "4. g - 1 so far\n",
            "5. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"crisp\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"c\"s in the word \"crisp\"\n",
            "1. c - 1 so far\n",
            "2. r - 1 so far\n",
            "3. i - 1 so far\n",
            "4. s - 1 so far\n",
            "5. p - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"b\" are there in the word \"fusion\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of \"b\"s in the word \"fusion\"\n",
            "1. f - 0 so far\n",
            "2. u - 0 so far\n",
            "3. s - 0 so far\n",
            "4. i - 0 so far\n",
            "5. o - 0 so far\n",
            "6. n - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"o\" are there in the word \"wisp\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of \"o\"s in the word \"wisp\"\n",
            "1. w - 0 so far\n",
            "2. i - 0 so far\n",
            "3. s - 0 so far\n",
            "4. p - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"elude\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of \"s\"s in the word \"elude\"\n",
            "1. e - 0 so far\n",
            "2. l - 0 so far\n",
            "3. u - 0 so far\n",
            "4. d - 0 so far\n",
            "5. e - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"orchard\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"h\"s in the word \"orchard\"\n",
            "1. o - 0 so far\n",
            "2. r - 0 so far\n",
            "3. c - 0 so far\n",
            "4. h - 1 so far\n",
            "5. a - 1 so far\n",
            "6. r - 1 so far\n",
            "7. d - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"e\"s in the word \"mantle\"\n",
            "1. m - 0 so far\n",
            "2. a - 0 so far\n",
            "3. n - 0 so far\n",
            "4. t - 0 so far\n",
            "5. l - 0 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"q\" are there in the word \"ivory\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of \"q\"s in the word \"ivory\"\n",
            "1. i - 0 so far\n",
            "2. v - 0 so far\n",
            "3. o - 0 so far\n",
            "4. r - 0 so far\n",
            "5. y - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"prelude\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "Counting the number of \"e\"s in the word \"prelude\"\n",
            "1. p - 0 so far\n",
            "2. r - 0 so far\n",
            "3. e - 1 so far\n",
            "4. l - 1 so far\n",
            "5. u - 1 so far\n",
            "6. d - 1 so far\n",
            "7. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"enchant\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"t\"s in the word \"enchant\":\n",
            "1. e - 0 so far\n",
            "2. n - 0 so far\n",
            "3. c - 0 so far\n",
            "4. h - 0 so far\n",
            "5. a - 0 so far\n",
            "6. n - 0 so far\n",
            "7. t - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"oath\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"a\"s in the word \"oath\":\n",
            "1. o - 0 so far\n",
            "2. a - 1 so far\n",
            "3. t - 1 so far\n",
            "4. h - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"m\"s in the word \"mantle\":\n",
            "1. m - 1 so far\n",
            "2. a - 1 so far\n",
            "3. n - 1 so far\n",
            "4. t - 1 so far\n",
            "5. l - 1 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"oath\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"h\"s in the word \"oath\":\n",
            "1. o - 0 so far\n",
            "2. a - 0 so far\n",
            "3. t - 0 so far\n",
            "4. h - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"rust\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"s\"s in the word \"rust\":\n",
            "1. r - 0 so far\n",
            "2. u - 0 so far\n",
            "3. s - 1 so far\n",
            "4. t - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"sapphire\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"a\"s in the word \"sapphire\":\n",
            "1. s - 0 so far\n",
            "2. a - 1 so far\n",
            "3. p - 1 so far\n",
            "4. h - 1 so far\n",
            "5. e - 1 so far\n",
            "6. i - 1 so far\n",
            "7. r - 1 so far\n",
            "8. a - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"n\"s in the word \"mantle\":\n",
            "1. m - 0 so far\n",
            "2. a - 0 so far\n",
            "3. n - 1 so far\n",
            "4. t - 1 so far\n",
            "5. l - 1 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"veto\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of \"r\"s in the word \"veto\":\n",
            "1. v - 0 so far\n",
            "2. e - 0 so far\n",
            "3. t - 0 so far\n",
            "4. o - 0 so far\n",
            "Therefore, the number of times \"r\" appears in the word \"veto\" is:\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"l\" are there in the word \"resolve\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"l\"s in the word \"resolve\":\n",
            "1. r - 0 so far\n",
            "2. o - 0 so far\n",
            "3. l - 1 so far\n",
            "4. e - 1 so far\n",
            "5. v - 1 so far\n",
            "6. s - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"orchard\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"c\"s in the word \"orchard\":\n",
            "1. o - 0 so far\n",
            "2. r - 0 so far\n",
            "3. c - 1 so far\n",
            "4. h - 1 so far\n",
            "5. a - 1 so far\n",
            "6. r - 1 so far\n",
            "7. d - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"fathom\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"t\"s in the word \"fathom\":\n",
            "1. f - 0 so far\n",
            "2. a - 0 so far\n",
            "3. t - 1 so far\n",
            "4. h - 1 so far\n",
            "5. o - 1 so far\n",
            "6. m - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"elude\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "Counting the number of \"e\"s in the word \"elude\":\n",
            "1. e - 1 so far\n",
            "2. l - 1 so far\n",
            "3. u - 1 so far\n",
            "4. d - 1 so far\n",
            "5. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"grim\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"r\"s in the word \"grim\":\n",
            "1. g - 0 so far\n",
            "2. r - 1 so far\n",
            "3. i - 1 so far\n",
            "4. m - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"fusion\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"i\"s in the word \"fusion\":\n",
            "1. f - 0 so far\n",
            "2. u - 0 so far\n",
            "3. s - 0 so far\n",
            "4. i - 1 so far\n",
            "5. o - 1 so far\n",
            "6. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"o\" are there in the word \"aperture\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of \"o\"s in the word \"aperture\":\n",
            "1. a - 0 so far\n",
            "2. p - 0 so far\n",
            "3. t - 0 so far\n",
            "4. r - 0 so far\n",
            "5. e - 0 so far\n",
            "6. u - 0 so far\n",
            "7. r - 0 so far\n",
            "8. e - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"knack\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"n\"s in the word \"knack\":\n",
            "1. k - 0 so far\n",
            "2. n - 1 so far\n",
            "3. a - 1 so far\n",
            "4. c - 1 so far\n",
            "5. k - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"capture\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"c\"s in the word \"capture\":\n",
            "1. c - 1 so far\n",
            "2. a - 1 so far\n",
            "3. p - 1 so far\n",
            "4. t - 1 so far\n",
            "5. u - 1 so far\n",
            "6. r - 1 so far\n",
            "7. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "time: 39min 21s (started: 2025-12-26 20:32:57 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Now let's train for real! Let's do a longer training that will take an hour or more\n",
        "# Note: If this run is successful, you can consider doing a longer train\n",
        "# to see what happens, but that's beyond the scope of this project.\n",
        "# TODO: Fill out the areas where you find **********\n",
        "\n",
        "# Full training\n",
        "training_args = GRPOConfig(\n",
        "    **COMMON_GRPO_TRAINING_PARAMS,\n",
        "    max_steps=50,\n",
        ")\n",
        "trainer = GRPOTrainer(\n",
        "    model=model,\n",
        "    processing_class=tokenizer,\n",
        "    reward_funcs=REWARD_FUNCS,\n",
        "    args=training_args,\n",
        "    train_dataset=ds,\n",
        ")\n",
        "trainer_res = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "available columns: dict_keys(['loss', 'grad_norm', 'learning_rate', 'num_tokens', 'completions/mean_length', 'completions/min_length', 'completions/max_length', 'completions/clipped_ratio', 'completions/mean_terminated_length', 'completions/min_terminated_length', 'completions/max_terminated_length', 'rewards/numbering_reward_func/mean', 'rewards/numbering_reward_func/std', 'rewards/spelling_reward_func/mean', 'rewards/spelling_reward_func/std', 'rewards/counting_reward_func/mean', 'rewards/counting_reward_func/std', 'rewards/format_reward_func/mean', 'rewards/format_reward_func/std', 'rewards/correct_answer_reward_func/mean', 'rewards/correct_answer_reward_func/std', 'reward', 'reward_std', 'frac_reward_zero_std', 'completion_length', 'kl', 'epoch', 'step'])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 136 ms (started: 2025-12-26 21:23:21 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Show the total (sum) of the rewards as well as the correct_answer_reward_func (means with in the batch)\n",
        "# Do you see the rewards increasing? Does the model get the correct answer\n",
        "# more frequently toward the end?\n",
        "# No changes needed in this cell\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# If you want to graph other columns, check these out\n",
        "print(f\"available columns: {trainer.state.log_history[0].keys()}\")\n",
        "\n",
        "log_df = pd.DataFrame(trainer.state.log_history)\n",
        "log_df[\"reward\"].plot()\n",
        "log_df[\"rewards/correct_answer_reward_func/mean\"].plot()\n",
        "\n",
        "# Show the legend\n",
        "plt.legend([\"reward\", \"rewards/correct_answer_reward_func/mean\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View the results\n",
        "Now let's try the model we just trained!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 917 ms (started: 2025-12-26 21:23:49 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Save the LoRA adapters\n",
        "# No changes needed in this cell\n",
        "\n",
        "# Save the LoRA model\n",
        "model.save_lora(\"grpo_saved_lora\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 910 Î¼s (started: 2025-12-26 21:23:53 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Create a function to run both the original model and the updated model\n",
        "# No changes needed in this cell\n",
        "\n",
        "\n",
        "def compare_old_and_new_model(messages):\n",
        "    from vllm import SamplingParams\n",
        "\n",
        "    text = tokenizer.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    sampling_params = SamplingParams(\n",
        "        temperature=0.8,\n",
        "        top_p=0.95,\n",
        "        max_tokens=1024,\n",
        "    )\n",
        "    old = (\n",
        "        model.fast_generate(\n",
        "            text,\n",
        "            sampling_params=sampling_params,\n",
        "        )[0]\n",
        "        .outputs[0]\n",
        "        .text\n",
        "    )\n",
        "\n",
        "    new = (\n",
        "        model.fast_generate(\n",
        "            text,\n",
        "            sampling_params=sampling_params,\n",
        "            lora_request=model.load_lora(\"grpo_saved_lora\"),\n",
        "        )[0]\n",
        "        .outputs[0]\n",
        "        .text\n",
        "    )\n",
        "\n",
        "    print(\"===OLD===\\n\")\n",
        "    print(old)\n",
        "\n",
        "    print(\"\\n\\n===NEW===\\n\")\n",
        "    print(new)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compare the old and new models on the letter-counting task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1040.51it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.69s/it, est. speed input: 62.38 toks/s, output: 38.62 toks/s]\n",
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1178.84it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.02s/it, est. speed input: 51.98 toks/s, output: 33.17 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== PROMPT ===\n",
            "[{'content': \"\\nRespond in the following format:\\n<reasoning>\\nCounting the number of [letter_to_count]'s in the word [word]\\n1. [first letter] - [count of requested letter so far] so far\\n2. [second letter] - [count of requested letter so far] so far\\n...\\n</reasoning>\\n<answer>\\n[number]\\n</answer>\\n\", 'role': 'system'}, {'content': 'How many of the letter \"a\" are there in the word \"idea\"', 'role': 'user'}]\n",
            "\n",
            "=== OLD MODEL (before GRPO) ===\n",
            "<reasoning>\n",
            "Counting the number of a's in the word idea\n",
            "1. i - 0 so far\n",
            "2. d - 1 so far\n",
            "3. e - 2 so far\n",
            "4. a - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "\n",
            "=== NEW MODEL (after GRPO) ===\n",
            "<reasoning>\n",
            "Counting the number of \"a\"s in the word \"idea\":\n",
            "1. i - 0 so far\n",
            "2. d - 0 so far\n",
            "3. e - 0 so far\n",
            "4. a - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "time: 3.72 s (started: 2025-12-26 21:37:53 +00:00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's try spelling the first word from the dataset\n",
        "# TODO: Fill out the areas where you find **********\n",
        "\n",
        "# Load the first item from the dataset (index 0) and compare the old and new models\n",
        "# **********\n",
        "old_model = model.fast_generate(\n",
        "    tokenizer.apply_chat_template(\n",
        "        ds[0][\"prompt\"], tokenize=False, add_generation_prompt=True\n",
        "    ),\n",
        "    sampling_params=SamplingParams(temperature=0.8, top_p=0.95, max_tokens=1024),\n",
        ")\n",
        "\n",
        "new_model = model.fast_generate(\n",
        "    tokenizer.apply_chat_template(\n",
        "        ds[0][\"prompt\"], tokenize=False, add_generation_prompt=True\n",
        "    ),\n",
        "    sampling_params=SamplingParams(temperature=0.8, top_p=0.95, max_tokens=1024),\n",
        "    lora_request=model.load_lora(\"grpo_saved_lora\"),\n",
        ")\n",
        "\n",
        "# Print the prompt\n",
        "print(\"=== PROMPT ===\")\n",
        "print(ds[0][\"prompt\"])\n",
        "print()\n",
        "\n",
        "# Print the old model output (before fine-tuning)\n",
        "print(\"=== OLD MODEL (before GRPO) ===\")\n",
        "print(old_model[0].outputs[0].text)\n",
        "print()\n",
        "\n",
        "# Print the new model output (after fine-tuning)\n",
        "print(\"=== NEW MODEL (after GRPO) ===\")\n",
        "print(new_model[0].outputs[0].text)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our model is better at spelling and counter letters in words! Depending on your reward functions, the size of your model, and the amount of steps trained, results may vary.\n",
        "\n",
        "For about an hour of training time, your model may not be perfect (or maybe it is), but it's definitely moving in the right direction!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Make sure the model did not forget basic facts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1198.37it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.65it/s, est. speed input: 95.95 toks/s, output: 21.32 toks/s]\n",
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1151.96it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.96it/s, est. speed input: 70.85 toks/s, output: 15.74 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===OLD===\n",
            "\n",
            "The capital of France is Paris.\n",
            "\n",
            "\n",
            "===NEW===\n",
            "\n",
            "The capital of France is Paris.\n",
            "time: 899 ms (started: 2025-12-26 21:36:33 +00:00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's see if the model still remembers some of the facts from its original training\n",
        "# TODO: Fill out the areas where you find **********\n",
        "\n",
        "# Ask both the old and new models a question the model is likely to know,\n",
        "# e.g. a well-known capital city\n",
        "compare_old_and_new_model([\n",
        "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Great job! Congrats on completing the project! ðŸŽ‰ðŸ¤—"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
